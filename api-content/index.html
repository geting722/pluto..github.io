{"posts":[{"title":"一次生产 Full GC 排查过程","content":" 转载：https://www.xiaoshuang.fun/%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7-full-gc-%E6%8E%92%E6%9F%A5%E8%BF%87%E7%A8%8B#eabe4b5e5bae4da7a0315603458af417 觉得写的很好 JVM 知识回顾 由于我们的项目线上使用的是 ****ParNew 和 CMS ，****所以我们先来简单回顾一下相关的基础知识。 ParNew 收集器 ParNew 收集器其实就是 Serial 收集器的多线程版本。除了使用多线程外其余行为均和 Serial 收集器一模一样（参数控制、收集算法、Stop The World、对象分配规则、回收策略等）。 特点：多线程、ParNew 收集器默认开启的收集线程数与 CPU 的数量相同，在 CPU 非常多的环境中，可以使用-XX:ParallelGCThreads参数来限制垃圾收集的线程数。和 Serial 收集器一样存在 Stop The World 问题。 应用场景：ParNew 收集器是许多运行在 Server 模式下的虚拟机中首选的新生代收集器，因为它是除了 Serial 收集器外，唯一一个能与 CMS 收集器配合工作的。 CMS 收集器 CMS牺牲了系统的吞吐量来追求收集速度，适合追求垃圾收集速度的服务器上。 特点：基于标记-清除算法实现。并发收集、低停顿。 应用场景：适用于注重服务的响应速度，希望系统停顿时间最短，给用户带来更好的体验等场景下。如 web 程序、b/s 服务。 CMS收集器的运行过程分为下列4步： 初始标记：标记 GC Roots 能直接找到的对象。速度很快但是仍存在 Stop The World 问题 并发标记：进行GC Roots Tracing 的过程，找出存活对象且与用户线程可并发执行。 重新标记：为了修正并发标记期间因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录。仍然存在 Stop The World 问题。 并发清除：对标记的对象进行清除回收。 JVM 内存模型 这里放张图，大家在回顾下就不做过多介绍了 JVM 常用参数 常见的如下： Xms64m 初始堆内存 64m. Xmx128m 最大堆内存 128m. Xmn32m 年轻代内存 32m. -XX:+UseParNewGC 新生代使用并行收集器. -XX:+UseConcMarkSweepGC 老年代使用 cms 收集器. Xss=256k 线程栈大小. -XX:+PrintGCDetails 打印 GC 详情. XX:+HeapDumpOnOutOfMemoryError 发送内存溢出时 dump 内存. -XX:NewRatio=2新生代和老年代的默认比例为 1:2，也就是说新生代占用 1/3的堆内存，而老年代占用 2/3 的堆内存。可以通过参数 -XX:NewRatio=2 来设置老年代/新生代的比例. 背景描述 上次一个新项目在经历过生产压测后发现一个问题，那就是系统的 cpu 占用率特别高。在达到一定的 QPS 的时候，cpu 占用率高达 80%-90% ,这是意料之外的，所以压测结果也并没有达到预期。因为这个时候系统层面没有任何优化，是直接调用数据库裸奔。所以怀疑可能是因为查询数据和处理数据时间比较长导致请求阻塞。 由于在生产压测，线程快照、内存快照都没有来的及保存就及时恢复生产状态了 在这之后我还单独在本地压测下接口，想要试着复现下 cpu 占用的问题，由于环境差异比较大，并没有发现什么问题。于是就继续进行优化和容灾的建设了。在经历过压测后，又有新的需求接入上线了，导致流量大幅增长。问题就开始暴露出来了。 问题现象 现象一：cpu 飙升 现象二：系统响应耗时增加 现象三：内存使用率下降 排查步骤 发现生产又出现 cpu 飙升的情况，就赶快登录出现问题的机器，通过以下步骤进行排查。 步骤一：登录服务器查找 cpu 占用率高的进程 首先登录到服务器后 通过 top 命令，我们可以查看当前 cpu 占用率最高的进程，从图中我们可以看出 pid 324023 的这个进程占用的 cpu 使用率比较高，实际生产可能高达 99%。这个截图是我为了演示模拟的。 步骤二：找到进程中占用 cpu 最多的线程 我们继续从 pid 324023 中找到占用 cpu 最多的线程，可以使用 top -H -p 324023 命令来查看 假设 pid 324089 就是我们找到的 cpu 占用率最高的线程，我就简单粗暴的使用 jstack 命令将线程快照打印出来了，后面使用分析工具进行分析。使用以下命令： 通过分析工具发现，我擦 ，啥情况线程都 Blocked 了。我们来看下线程什么情况下会进入 Blocked 状态。 阻塞状态（Blocked） 阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种： 等待阻塞：运行的线程执行wait()方法，JVM会把该线程放入等待池中。 同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池中。 其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。 步骤三：*查看 JVM 内存情况* 通过 jmap -heap 324089 命令查看内存的使用情况，突发发现 Eden 、S0、S1 都没有使用…… 带着这个疑问，我们进行下一步排查。 步骤四：查看日志、内存快照 gc 日志 通过步骤三发现 是不是 内存分配 出现了问题，于是就赶快去看 gc 日志，我到线上的服务把 gc 日志和 heap dump 都下载到本地，方便进行分析。 通过分析工具我们看下内存的分配，发现 Meta Space 已经分配了 1.13g 的内存了，这个值已经远远超出设置的最大值了，系统中设置 -XX:MaxMetaspaceSize=160m。 从 JDK8 开始，JVM 将原来存放 klass 元数据的永久代 Perm 换成了本地元空间 Metaspace，Perm 时期会为klass元数据分配一块内存，如果设置不够用就会抛出 OOM，Metaspace 的出现希望能解决这个问题，Metaspace 确实可以最大限度来使用堆外的内存，但是挺遗憾，还是有一些参数会导致 Metaspace 抛出 OOM。 通过这个图发现 Full GC 一直在持续，几乎没有间断，这就说明为啥前边看内存时新生代没有内存分配了，因为这里一直在 Full GC 导致工作线程一直在暂停，无法运行。所以请求就开始阻塞响应时间超时、cpu就开始飙升、内存就开始下降，正好应对了前边说到的 3 个现象。 接下来在看 GC 的原因，这里给出了3个原因： Last ditch collection 当JVM无法为应该存储在元空间中的东西分配内存时，它首先运行GC。它将导致“元数据GC阈值”GC。如果这个GC不能释放空间，那么尝试扩展元空间。如果仍然无法创建空闲空间，则GC将以“Last ditch collection”为由触发。如果仍然没有足够的空闲空间，则抛出OutOfMemoryError。 Metadata GC Threshold 这种类型的GC事件在以下两种情况下触发: 配置的元空间大小小于实际需求 存在类加载器泄漏 (非常不可能，但有可能) Concurrent Mode Failure CMS收集器使用一个或多个垃圾收集器线程，这些线程与应用程序线程同时运行，目标是在旧代变得满之前完成对它的收集。CMS收集器在应用程序线程仍然运行的情况下执行大部分跟踪和清理工作，因此应用程序线程只能看到短暂的暂停。但是，如果CMS收集器无法在老一代填满之前完成回收不可达对象，或者如果分配不能满足于老一代中的可用空闲空间块，那么应用程序将暂停并完成收集。不能同时完成收集被称为并发模式失败，这表明需要调整CMS收集器参数。并发模式失败通常触发Full GC。 通过上边的内存分配综合来分析 元空间分配了 1.13g ，在加上 GC 原因 Metadata GC Threshold，所以可以看出本次的 GC 就是因为元空间分配的问题引起的。 内存快照 通过 gc 日志的分析，可以看出我们的 gc 是通过元空间引起的，gc原因中提到过 Metadata GC Threshold 发生的情况，其中有一个是类加载泄露。我们把从服务器下载下来的 heap dump 文件通过 IBM HeapAnalyzer 来分析下。 通过内存快照分析，发现了个不一样的Classloader：AviatorClassLoader ，看到这里想起来了，由于项目中有些动态规则的执行，所以使用开源框架 aviatorscript **。**于是就去查找项目代码，找到编译执行规则的地方，发现是使用不当，造成每次调用规则都会产生大量的匿名类。 AviatorScript 是一门高性能、轻量级寄宿于 JVM （包括 Android 平台）之上的脚本语言。 复现demo 这个规则的含义是 通过输入3个参数 a、b、c，计算三个参数的和。我们通过AviatorEvaluator#execute(java.lang.String, java.util.Map&lt;java.lang.String,java.lang.Object&gt;, boolean) 方法执行表达式，这个方法内部是不会缓存编译结果的。在追踪源码中可以看到,如果没有缓存，每次调用都会生成一个匿名 AviatorClassLoader 类返回。 也就是说每个请求调用规则的时候都是先编译在执行，并且会创建大量的匿名 AviatorClassLoader，所以才会导致 Metaspace 的占用内存一直扩大，最终导致频繁 Full GC。到此这个 Full GC 的问题终于查明白了。 本文只是简单叙述了下排查问题的过程，其中有大量的基础知识和过程并没有详细说明，也不是一篇文章能够明白的，如果有一些错误还望大家见谅和指正 ","link":"https://plutoyty.github.io/post/qg7gisV15/"},{"title":"Go生态系统常见的项目布局模式","content":"Go目录： /cmd 项目主要的应用程序。 对于每个应用程序来说这个目录的名字应该和项目可执行文件的名字蔡徐坤匹配（例如，/cmd/myapp）。 不要在这个目录中放太多的代码。如果目录中的代码可以被其他项目导入并使用，那么应该把他们放在/pkg目录。如果目录中的代码不可重用，或者不希望被他人使用，应该将代码放在/internal目录。显式地表明意图比较好！ 通常来说，项目都应该拥有一个小的main函数，并在main函数中导入或者调用/internal和/pkg目录中的代码。 Examples: https://github.com/vmware-tanzu/velero/tree/main/cmd (just a really small main function with everything else in packages) https://github.com/moby/moby/tree/master/cmd https://github.com/prometheus/prometheus/tree/main/cmd https://github.com/influxdata/influxdb/tree/master/cmd https://github.com/kubernetes/kubernetes/tree/master/cmd https://github.com/dapr/dapr/tree/master/cmd https://github.com/ethereum/go-ethereum/tree/master/cmd /internal 私有的应用程序代码库。这些是不希望被其他人导入的代码。请注意：这种模式是Go编译器强制执行的。详细内容情况Go 1.4的release notes。再次注意，在项目的目录树中的任意位置都可以有internal目录，而不仅仅是在顶级目录中。 可以在内部代码包中添加一些额外的结构，来分隔共享和非共享的内部代码。这不是必选项（尤其是在小项目中），但是有一个直观的包用途是很棒的。应用程序实际的代码可以放在/internal/app目录（如，internal/app/myapp），而应用程序的共享代码放在/internal/pkg目录（如，internal/pkg/myprivlib）中。 /pkg 外部应用程序可以使用的库代码（如，/pkg/mypubliclib）。其他项目将会导入这些库来保证项目可以正常运行，所以在将代码放在这里前，一定要三思而行。请注意，internal目录是一个更好的选择来确保项目私有代码不会被其他人导入，因为这是Go强制执行的。使用/pkg目录来明确表示代码可以被其他人安全的导入仍然是一个好方式。Travis Jeffery撰写的关于 I’ll take pkg over internal 文章很好地概述了pkg和inernal目录以及何时使用它们。 当您的根目录包含大量非Go组件和目录时，这也是一种将Go代码分组到一个位置的方法，从而使运行各种Go工具更加容易（在如下的文章中都有提到：2018年GopherCon Best Practices for Industrial Programming，Kat Zien - How Do You Structure Your Go Apps ，Golab 2018 Massimiliano Pippi - Project layout patterns in Go）。 点击查看/pkg就能看到那些使用这个布局模式的流行Go代码仓库。这是一种常见的布局模式，但未被普遍接受，并且Go社区中的某些人不推荐这样做。 如果项目确实很小并且嵌套的层次并不会带来多少价值（除非你就是想用它），那么就不要使用它。请仔细思考这种情况，当项目变得很大，并且根目录中包含的内容相当繁杂（尤其是有很多非Go的组件）。 /vendor 应用程序的依赖关系（通过手动或者使用喜欢的依赖管理工具，如新增的内置Go Modules特性）。执行go mod vendor命令将会在项目中创建/vendor目录，注意，如果使用的不是Go 1.14版本，在执行go build进行编译时，需要添加-mod=vendor命令行选项，因为它不是默认选项。 构建库文件时，不要提交应用程序依赖项。 请注意，从1.13开始，Go也启动了模块代理特性（使用https：//proxy.golang.org作为默认的模块代理服务器）。点击这里阅读有关它的更多信息，来了解它是否符合所需要求和约束。如果Go Module满足需要，那么就不需要vendor目录。 服务端应用程序的目录 /api OpenAPI/Swagger规范，JSON模式文件，协议定义文件。 更多样例查看/api目录。 Web应用程序的目录 /web Web应用程序特定的组件：静态Web资源，服务器端模板和单页应用（Single-Page App，SPA）。 通用应用程序的目录 /configs 配置文件模板或默认配置。 将confd或者consul-template文件放在这里。 /init 系统初始化（systemd、upstart、sysv）和进程管理（runit、supervisord）配置。 /scripts 用于执行各种构建，安装，分析等操作的脚本。 这些脚本使根级别的Makefile变得更小更简单（例如https://github.com/hashicorp/terraform/blob/main/Makefile）。 更多样例查看/scripts。 /build 打包和持续集成。 将云（AMI），容器（Docker），操作系统（deb，rpm，pkg）软件包配置和脚本放在/build/package目录中。 将CI（travis、circle、drone）配置文件和就脚本放在build/ci目录中。请注意，有一些CI工具（如，travis CI）对于配置文件的位置有严格的要求。尝试将配置文件放在/build/ci目录，然后链接到CI工具想要的位置。 /deployments IaaS，PaaS，系统和容器编排部署配置和模板（docker-compose，kubernetes/helm，mesos，terraform，bosh）。请注意，在某些存储库中（尤其是使用kubernetes部署的应用程序），该目录的名字是/deploy。 /test 外部测试应用程序和测试数据。随时根据需要构建/test目录。对于较大的项目，有一个数据子目录更好一些。例如，如果需要Go忽略目录中的内容，则可以使用/test/data或/test/testdata这样的目录名字。请注意，Go还将忽略以“.”或“_”开头的目录或文件，因此可以更具灵活性的来命名测试数据目录。 更多样例查看/test。 其他 /docs 设计和用户文档（除了godoc生成的文档）。 更多样例查看/docs。 /tools 此项目的支持工具。请注意，这些工具可以从/pkg和/internal目录导入代码。 更多样例查看/tools。 /examples 应用程序或公共库的示例。 更多样例查看/examples。 /third_party 外部辅助工具，fork的代码和其他第三方工具（例如Swagger UI）。 /githooks Git的钩子。 /assets 项目中使用的其他资源（图像，Logo等）。 /website 如果不使用Github pages，则在这里放置项目的网站数据。 更多样例查看/website。 不应该出现的目录 /src 有一些Go项目确实包含src文件夹，但通常只有在开发者是从Java（这是Java中一个通用的模式）转过来的情况下才会有。如果可以的话请不要使用这种Java模式。你肯定不希望你的Go代码和项目看起来像Java。 不要将项目级别的/src目录与Go用于其工作空间的/src目录混淆，就像How to Write Go Code中描述的那样。$GOPATH环境变量指向当前的工作空间（默认情况下指向非Windows系统中的$HOME/go）。此工作空间包括顶级/pkg，/bin和/src目录。实际的项目最终变成/src下的子目录，因此，如果项目中有/src目录，则项目路径将会变成：/some/path/to/workspace/src/your_project/src/your_code.go。请注意，使用Go 1.11，可以将项目放在GOPATH之外，但这并不意味着使用此布局模式是个好主意。 参考：https://github.com/golang-standards/project-layout/blob/master/README_zh-CN.md ​ https://medium.com/golang-learn/go-project-layout-e5213cdcfaa2 ","link":"https://plutoyty.github.io/post/QU8xDlK87/"},{"title":"Context剖析","content":" Context 为同一任务的多个 goroutine 之间提供了 退出信号通知 和 元数据传递的功能。 针对Context的使用建议，Go官方提到了下面几点： 不要将 Context 塞到结构体里。直接将 Context 类型作为函数的第一参数，而且一般都命名为 ctx。 不要向函数传入一个 nil 的 context，如果你实在不知道传什么，标准库的TODO方法给你准备好了一个 emptyCtx。 不要把本应该作为函数参数的类型塞到 context 中，context 存储的应该是一些在 goroutine 共享的数据，比如Server的信息等等。 作者：kevinyan 链接：https://juejin.cn/post/7000300756116963342 来源：稀土掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 ","link":"https://plutoyty.github.io/post/R29SmM0SY/"},{"title":"协程的取消","content":"Go 语言中的协程可以通过多种方式退出，以下是几种常见的方式： 自然结束 协程的执行函数正常结束，协程自然退出。这种情况下，协程会自动释放相关资源，无需手动退出。 使用 channel 通知退出 在协程中创建一个 channel，当需要退出时，向该 channel 中发送一个信号。其他协程可以通过从该 channel 中读取信号来得知该协程需要退出，从而进行清理工作。示例代码如下： 在这个例子中，协程会不断地执行任务，但通过 select 语句监听了 quit channel，当该 channel 中有数据时，协程会退出。 使用 context 取消 在使用 Go 1.7 及以上版本时，可以使用 context 包来控制协程的取消。context 可以用来传递取消信号，当接收到取消信号时，协程可以做清理工作并退出。示例代码如下： 在这个例子中，使用 context.Background() 创建了一个根 context，然后使用 context.WithCancel() 创建了一个可以取消的子 context。协程中通过 select 语句监听了 ctx.Done()，当该 context 接收到取消信号时，协程会退出。 ","link":"https://plutoyty.github.io/post/tfLs-thzd/"},{"title":"Golang笔试题","content":" 先说成果 满分63 拿到46.75 自己来说不是特别满意 有一些是以前没有注意到的，也有粗心选错的 ；说白了就是自己水平不够，但是错过的题以后是不能再错了 错题 （为了方便直接截出来了） \\image-20230223203020650.png) 写出下面代码输出内容：________。 A. 打印前 B. 打印中 C. 打印后 D. panic: 触发异常 应该选ABCD 忽略了D自己也要打印 答对的 ","link":"https://plutoyty.github.io/post/Aqt2OF9WV/"},{"title":"大厂程序员是怎么用Redis的","content":"什么是Redis 为什么需要Redis？ 数据从单表，演进出了分库分表<!-- more --> MySQL从单机演进出了集群 数据量增长 读写数据压力的不断增加 数据分为冷数据和热数据， 将热数据放到内存当中 Redis基本原理 数据从内存读写，数据保存到硬盘防止重启数据丢失 增量数据保存到AOF文件 全量数据保存到RDB文件中 单线程处理所有命令 重启时根据AOF和RDB文件恢复数据，先从RDB文件中去读取，然后去AOF中看看是不是有漏的，如果有漏的就补到RDB文件中去。 为什么 Redis 是单线程的，却能有很好的性能(根据 Amdahl’s Law，优化耗时占比大的过程，才更有意义)，两句话概括是：Redis 利用了多路 I/O 复用机制，处理客户端请求时，不会阻塞主线程；Redis 单纯执行（大多数指令）一个指令不到 1 微秒，如此，单核 CPU 一秒就能处理 1 百万个指令（大概对应着几十万个请求吧），用不着实现多线程 Redis应用案例 1.连续签到 掘金每日连续签到 用户每日有一次签到的机会，如果断签，连续签到计数将归0。 连续签到的定义:每天必须在23:59:59前签到 String数据结构 数据结构-sds 可以存储字符串、数字、二进制数据 通常和expire配合使用 场景:存储计数、Session len 代表字符串长度 alloc 表示buf的长度 flags 表示sds的类型，因为存储空间不同，SDS类型也不同，有很多不同类型的SDS，例如16位、32位，和len用于获取value 2.消息通知 用list作为消息队列 使用场景: 消息通知。 例如当文章更新时，将更新 后的文章推送到ES,用户就 能搜索到最新的文章数据 List数据结构Quicklist Quucklist由双向链表和listpack实现 因为Redis尽可能的去节省空间，所有一个entry里面包含了很多节点 listpack 3.计数 一个用户有多项计数需求， 可通过hash结构存储 Hash数据结构Dict 4.排行榜 积分变化时，排名要实时变更 结合dict后，可实现通过key操作跳表的功能 ZINCRBY myzset 2 &quot;Alex ZSCORE myzset &quot;Alex&quot; zsikplist数据结构 跳表和dict实现 5.限流 要求1秒内放行的请求为N,超过N则禁止访问 Key: comment_freq_ limit_1671356046 对这个Key调用incr,超过限制N则禁止访问 1671356046是当前时间戳 6.分布式锁 并发场景，要求一次只能有一个协程执行。 执行完成后，其它等待中的协程才能执行。 可以使用redis的setnx实现， 利用了两个特性 Redis是单线程执行命令 setnx只有未设置过才能执行成功 Redis注意事项，常出现的问题 大key，热key问题 大key的定义 数据类型 大Key标准 String类型 value的字节数大于10KB即为大key Hash/Set/Zset/list等复杂数据结构类型 元素个数大于5000个或总value字节数大于10MB即为大key 大key的危害 读取成本高 容易导致慢查询(过期、删除) 主从复制异常，服务阻塞 无法正常响应请求 业务侧使用大Key的表现 请求Redis超时报错 消除大key 拆分 将大key拆分为小key。例如一个String拆分成多个String 压缩 将value压缩后写入redis,读取时解压后再使用。压缩算法可以是gzip、snappy、lz4等。通常情况下， 一个压缩算法压缩率高、则解压耗时就长。需要对实际数据进行测试后，选择一个合适的算法。 如果存储的是JSON字符串，可以考虑使用MessagePack进行序列化。 集合类结构hash、list、 set、 set 拆分:可以用hash取余、位掩码的方式决定放在哪个key中 区分冷热:如榜单列表场景使用zset,只缓存前10页数据，后续数据走db 热key 热Key的定义 用户访问一个Key的QPS特别高，导致Server实例出现CPU负载突增或者不均的情况。 热key没有明确的标准，QPS 超过500就有可能被识别为热Key 解决热key的方法 1.设置Localcache 在访问Redis前，在业务服务侧设置Localcache,降低访问Redis的QPS。LocalCache中 缓存过期或未命中， 则从Redis中将数据更新到ocalCache。Java的Guava、 Golang的Bigcache就 是这类LocalCache 2.拆分 将key:value这一个热Key复制写入多份，例如key1:value. key2:value,访问的时候访问多个key,但value是同一个，以此将qps分散到不同实例上，降低负载。代价是，更新时需要更新多个key,存在数据短暂不一致的风险 3. 使用Redis代理的热Key承载能力 字节跳动的Redis访问代理就具备热Key承载能力。本质上是结合了“热Key发现&quot;、&quot;LocalCache' 两个功能 慢查询场景 容易导致redis慢查询的操作 批量操作一次性传 入过多的key/value,如mset/hmset/sadd/zadd等 O(n)操作建议单批次不要超过100，超过100之 后性能下降明显。 zset大部分命令都是O(log(n))，当大小超过5k以上时，简单的zadd/zrem也可能导致慢查询 操作的单个value过大，超过10KB。 也即，避免使用大Key 缓存穿透，缓存雪崩 缓存穿透:热点数据查询绕过缓存，直接查询数据库 缓存雪崩:大量缓存同时过期 缓存穿透的危害 查询一个一定不存在的数据 通常不会缓存不存在的数据， 这类查询请求都会直接打到db，如果有系统bug或人为攻击， 那么容易导致db响应慢甚至宕机 缓存过期时 在高并发场景下，一个热key如果过期，会有大量请求同时击穿至db,容易影响db性能和稳定。 同一时间有大量key集中过期时，也会导致大量请求落到db上，导致查询变慢，甚至出现db无法响应新的查询 如何减少缓存穿透 缓存空值 如一个不存在的userID。这个id在缓存和数据库中都不存在。则可以缓存一个空值，下次再查缓存直接反回空值。 布隆过滤器 通过bloom filter算法来存储合法Key,得益于该算法超高的压缩率，只需占用极小的空间就能存储大量key值 如何避免缓存雪崩 缓存空值 将缓存失效时间分散开，比如在原有的失效时间基础上增加一个随机值，例如不同Key过期时间， 可以设置为10分1秒过期，10分23秒过期， 10分8秒过期。 单位秒部分就是随机时间，这样过期时间就分散了。 对于热点数据，过期时间尽量设置得长一些，冷门的数据可以相对设置过期时间短-些。 使用缓存集群，避免单机宕机造成的缓存雪崩。 ","link":"https://plutoyty.github.io/post/tnXMTwDiO/"},{"title":"mysql密码忘记怎么办","content":" 1.找到mysql配置文件 默认在 /etc/my.cnf 加两句话跳过权限验证 [mysqld] skip-grant-tables skip-grant-tables：跳过权限认证 不用验证就操作mysql 2.重启mysql service mysqld restart 3.进入mysql msyql -u root -p 4.进入mysql库 use msyql; 在这个中命令必须要有;才代表结束 5.修改密码 update user set authentication_string=password(&quot;密码&quot;) where user='用户; 刷新生效 flush privileges; 6.赋予用户权限 ALTER USER '用户'@'localhost' IDENTIFIED BY '密码'; 7.开启外界连接 比如navicat GRANT ALL PRIVILEGES ON . TO '用户'@'%'IDENTIFIED BY '密码' WITH GRANT OPTION; 刷新生效 flush privileges; 8.退出mysql exit 并且把之前改的配置文件恢复 ","link":"https://plutoyty.github.io/post/al2PADjFe/"},{"title":"RocketMQ安装会碰到的问题","content":" 这里就说明一下安装时踩过的坑，还有一些注意事项 对于前面的文章已经说明怎么安装了，这里在说明一下，因为这里的是5.0版本的的，步骤大致上都差不多，参考官网5.0的快速启动，会出现问题的地方 环境 JDK11,CentOS 7 对于官网参考的依赖： 对于这个,用官网提供的测试方法会报如下错误 换成 测试 生成者 消费者 ","link":"https://plutoyty.github.io/post/A35LlIHqN/"},{"title":"RocketMQ负载均衡","content":"消费者的负载均衡 一个Topic中的Queue只能有Consumer Group中的一个Consumer进行消费，那么他们之间的配对关系如何确定的，即Queue要分配给那个Consumer进行消费？也就是算法策略，常见有4中策略，这些策略通过创建Consumer时的构造器传进去的。 平均分配策略 计算公式： avg=QueueCount/ConsumerCountavg=QueueCount/ConsumerCount avg=QueueCount/ConsumerCount 若能整除，则按照avg个Queue诸葛分配Consumer，如果不能整除，将多于的Queue按照Consumer顺序逐个分配。 环形平均策略 环形平均算法是指，根据消费者的顺序，以此由Queue队列组成的环形图逐个分配 一致Hash策略 该算法会将consumer的hash值作为Node节点存放到hash环上，然后将queue的hash值也放到hash环上，顺时针方向距离queue最近的那个consumer就是该queue要分配的consumer。 问题： 分配效率较低，容易导致分配不均的情况 优点： 其可以有效减少由于消费者组扩容或缩容所带来的大量的Rebalance。 适合用在Consumer变化较频繁的场景 同机房策略 该算法会根据Queue的部署机房位置和Consumer的位置，过滤出当前相同机房的Queue，然后按照平均分配活环形平均策略对同机房的Queue进行分配，如果没有同机房的Queue，则会按照平均策略或者环形平均策略对所有的Queue进行分配 至少一次原则 每条消息必须要被成功消费一次。 成功消费：即Consumer在消费完消息后会向其消费进度记录器提交其消费消息的offset， offset被成功记录到记录器中 消费进度记录器：广播模式中的Consumer本身，集群模式的Broker 生产者的负载均衡： 对于无序消息，其Queue选择算法，也称为消息投递算法，常见的有两种： 轮询算法 默认选择算法。该算法保证了每个Queue中可以均匀的获取到消息。 该算法存在一个问题：由于某些原因，在某些Broker上的Queue可能投递延迟较严重。从而导致Producer的缓存队列中出现较大的消息积压，影响消息的投递性能。 最小投递延迟算法 该算法会统计每次消息投递的时间延迟，然后根据统计出的结果将消息投递到时间延迟最小的Queue。 如果延迟相同，则采用轮询算法投递。该算法可以有效提升消息的投递性能。 该算法也存在一个问题：消息在Queue上的分配不均匀。投递延迟小的Queue其可能会存在大量的消息。而对该Queue的消费者压力会增大，降低消息的消费能力，可能会导致MQ中消息的堆积。 ","link":"https://plutoyty.github.io/post/mwKclukbm/"},{"title":"RocketMQ集群的介绍和搭建","content":"各角色的职责 Producer: 消息的发送者;举例:发信者 Consumer: 消息接收者;举例:收信者 Broker: 暂存和传输消息;举例:邮局 NameServer: 管理Broker; 举例:各个邮局的管理机构 Topic: 区分消息的种类; 一个发送者可以发送消息给一个或者多个Topic; 一个消息的接收者可以订阅一个或者多个Topic消息 Message Queue:相当于是Topic的分区;用于并行发送和接收消息 分布式集群 集群特点 NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。 Broker部署相对复杂，Broker分 为Master与Slave, 一个Master可以对应多个Slave,但是个Slave只能对应一 个Master, Master与Slave的对应关系通过指定相同的BrokerName,不同的Brokerld来定义， Brokerld为0表示Master, 非0表示Slave。 Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接,定时注册Topic信息到所有NameServer。 Producer与NameServer集群中的其中一个节点(随机选择)建立长连接,定期从NameServer取Topic路由信息, 并向提供Topic 服务的Master建立长连接，且定时向Master发送心跳。 Producer完全无状态， 可集群部署。 Consumer与NameServer集群中的其中一个节点(随机选择)建立长连接,定期从NameServer取Topic路由信息，并向提供 Topic服务的Master. Slave建立长连接，且定时向Master. Slave发送心跳。Consumer既可以从Master订阅消息，也可以从 Slave订阅消息，订阅规则由Broker配置决定。 集群的模式 单Master模式 这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用。不建议线上环境使用，通常可以用于本地测试。 多Master模式 一个集群无Slave，全是Master，例如2个Master或者3个Master，这种模式的优缺点如下： 优点：配置简单，单个Master宕机或重启维护对应用无影响，在磁盘配置为RAID10时，即使机器宕机不可恢复情况下，由于RAID10磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢），性能最高。 缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。 多Master多Slave模式（异步） 每个Master配置一个Slave，有多对Master-Slave，HA采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优缺点如下： 优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多Master模式几乎一样。该模式的最大特点之一是，当master宕机后slave能够自动切换为master。不过由于slave从master的同步具有短暂的延迟（毫秒级），所以当master宕机后，这种异步复制方式可能会存在少量消息的丢失问题。 缺点：Master宕机，磁盘损坏情况下会丢失少量消息。 多Master多Slave模式（同步） 每个Master配置一个Slave，有多对Master-Slave，HA采用同步双写方式，即只有主备都写成功，才向应用返回成功，这种模式的优缺点如下： 优点：数据与服务都无单点故障，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高。 缺点：性能比异步复制模式略低（大约低10%左右），发送单个消息的RT会略高，且目前版本在主节点宕机后，备机不能自动切换为主机。 复制与刷盘策略 复制： 复制策略是Broker的Master与Slave间的数据同步方式。分为同步复制与异步复制： 同步复制：消息写入master后，master会等待slave同步数据成功后才向producer返回成功ACK 异步复制：消息写入master后，master立即向producer返回成功ACK，无需等待slave同步数据成功 异步复制降低系统写入延迟，提高吞吐量 刷盘： 刷盘策略指的是broker中消息的落盘方式，即消息发送到broker内存后消息持久化到磁盘的方式。分为同步刷盘与异步刷盘： 同步刷盘：当消息持久化到broker的磁盘后才算是消息写入成功。 异步刷盘：当消息写入到broker的内存后即表示消息写入成功，无需等待消息持久化到磁盘。 消息写入到Broker的内存，一般是PageCache，异步刷盘策略写入成功后立即返回ACK，但不会立即做落盘操作，而是当PageCache到达一定数量时，会自动进行落盘 工作流程 启动NameServer, NameServer起来后监听端口，等待Broker. Producer、 Consumer连 上来，相当于一个路由控制中心。 Broker启动，跟所有的NameServer保持长连接，然后每30秒向NameServer定时发送心跳包。心跳包中包含当前Broker信息(IP +端口等)以及存储所有Topic 信息。注册成功后，NameServer集群中就有 Topic跟Broker的映射关系。 Producer发送消息前，先创建Topic, 创建Topic时需要指定该Topic要存储在哪些Broker上,当然，在创建Topic时也会将Topic与Broker的关系写入到NameServer中。不过，这步是可选的，也可以在发送消息时自动创建Topic。 Producer发送消息，启动时先和NameServer集群中的其中一台建立长连接，并从NameServer中获取路由信息（当前发送的Topic消息的Queue与Broker的地址（IP+Port）的映射关系）。然后根据算法策略选择一个Queue，与队列所在的Broker建立长连接从而向Broker发消息。当然，在获取到路由信息后，Producer会首先将路由信息缓存到本地，再每30秒从NameServer更新一次路由信息。 Consumer跟Producer类似，启动时先和NameServer集群中的其中一台建立长连接，并从NameServer中获取路由信息（订阅Topic的路由信息）。然后根据算法策略从路由信息中获取到其所要消费的Queue，然后与队列所在的Broker建立长连接，开始消费其中的消息。Consumer在获取到路由信息后，同样也会每30秒从NameServer更新一次路由信息。不过不同于Producer的是，Consumer还会向Broker发送心跳，以确保Broker的存活状态。 双主双从的搭建 服务器环境 序号 IP 角色 架构模式 1 192.168.2.12 nameserver、brokerserver Master1、Slave2 2 192.168.2.13 nameserver、brokerserver Master2、Slave1 修改host文件 为什么要配置host文件呢，为了后面直接映射ip地址，host的优先级是比DNS的优先级是高的就不用每次讲解析为ip了。 配置完重启network 防火墙配置 配置防火墙主要也是把该打开的端口打开，当然最简单的方法就是关闭防火墙 但是学习环境还是可以这样做的，上线环境下这样做是给系统增加风险的，这里给出默认端口 nameserver 9876 master 10911 slave 11011 环境变量配置 配置了环境变量后就不用在bin下面支持了 配置完执行 创建消息存储路径 每一台服务器都创建一次 broker配置文件 master1 slave2 master2 slave1 修改启动脚本 这个上一篇文章下载 下来的时候其实已经讲过了 如果机器的内存不够的话就要改，大多数用的都是学生机或者虚拟机，需要根据内存大小进行适当的对JVM参数进行调整，这里也就成了必改项 runbroker.sh runserver.sh 服务启动 启动NameServer 分别启动所有的NameServer 启动broker master1 -c 是以某个配置文件启动，如果没有配置环境变量就要进入bin下执行 slave2 master2 slave1 查看进程状态 查看日志 管理工具 进入RocketMQ安装位置，在bin目录下执行./mqadmin {command} {args} 命令这里就不给出了 还有可视化管理工具，现在已经更新了， 地址 ：https://github.com/apache/rocketmq-dashboard 文档：https://rocketmq.apache.org/zh/docs/deploymentOperations/17Dashboard/ ","link":"https://plutoyty.github.io/post/8NJl7BbJt/"},{"title":"常用解压命令","content":"1、.tar 2、.gz 3、.tar.gz 和 .tgz 4、.bz2 5、.tar.bz2 6、.bz 7、.tar.bz 8、.Z 9、.tar.Z 10、.zip 11、.rar 12、.lha 13、.rpm ","link":"https://plutoyty.github.io/post/BJjPA3Cdw/"},{"title":"RocketMQ单master","content":" 前言：这里也可以用来作为RocketMQ的入门，安装和单master模式的搭建 为什么要用MQ 消息队列是一种先进先出的数据结构 应用解耦 可以将系统解耦，耦合度高的可以拆成诺干个子系统 流量削峰 这个就是一般用到最多的地方了，比如高并发场景下，平滑流量是200qps，峰值是1000qps，这个时候系统就抗不住了，可能会崩溃，如果增加硬件 数据分发 常用场景在分布式环境中，子系统需要另一个系统的消息 MQ的优缺点 优点就是上面为什么要用mq 缺点就是降低了系统可用性，mq宕机后依赖于mq的也全部宕掉了 提高了系统的复杂性 一致性问题 这里的一致性问题就是指，A系统处理完业务，通过B、C、D三个系统发消息数据，如果B系统、C系统处理成功，D系统处理失败，如何保证消息数据处理的一致性。 RocketMQ下载安装和使用 https://rocketmq.apache.org/download/ 常用命令 启动 1.启动NameServer 2.启动Broker RocketMQ默认内存很大，一般都会报错 修改配置文件调小内存 参考设置 关闭 对于 broker.conf 如果出现错误 修改配置 然后重启nameserver和broker 一定要先启动namesrv，因为消息服务器是注册到命名服务器上的，不先启动命名服务器怎么注册 再启动消息服务器，同时指定刚刚修改过的conf文件，不然还是会读取原本默认的阿里外网IP，还是会报错。 启动broker -n 指定的是注册到哪个消息服务器上 -c 指定的是刚刚修改的conf配置文件 测试RocketMQ 1.发送消息 2.接受消息 ","link":"https://plutoyty.github.io/post/n-xaBNOra/"},{"title":"高并发常用指标","content":"指标 1、QPS（Queries Per Second） 概念：服务器每秒处理查询次数，是一台服务器每秒能够处理的查询次数。用户发起查询请求到服务器做出响应这算一次，一秒内用户完成了50次查询请求，那此时服务器QPS就是50。 2、TPS （Transactions Per Second） 概念：服务器每秒处理的事务数，一个事物是用户发起查询请求到服务器做出响应这算一次。纳尼？这难道不是QPS的概念吗？划重点，这里就要说清楚一个概念了，在针对单接口，TPS可以认为是等价于QPS的，如访问 ‘order.html’ 这个页面而言,是一个TPS。而访问 ‘order.html’ 页面可能请求了3此服务器（如调用了css、js、order接口），这实际就算产生了三个QPS 所以，总结下就是，在针对单接口的时候TPS = QPS ,否则QPS就要看实际的请求次数了。 2、RT（Res（onse Time） 概念：响应实际，就是从客户端请求发起到服务器响应结果的时间。RT这个参数是系统最重要的指标之一，它的大小直接反应了当前系统的响应状态。基本和咱们用户体验息息相关，现在好一点监控系统一般都有三个RT，即平均、最大、最小。 一般系统RT 100ms 以内是比较正常的，300ms 勉强可以接受，1s的话再加上一些其他的外因，给用户的体验就是实实在在的不爽了。 3、并发数 概念：系统能同时处理的请求的数量，很多人经常会把并发数和TPS理解混淆。举例，请求一个index.html 页面，客户端发起了三个请求（css、js、index接口）,那么此时TPS =1 、QPS =3 、并发数 3。 SO，计算公式 ： QPS=并发数/RT || 并发数=QPS*RT 4、吞吐量（Throughput） 概念：每秒承受的用户访问量，吞吐量（系统能承受多少压力）和当前请求对CPU消耗、内存、IO使用等等紧密相关。单个请求消耗越高，系统吞吐量越低，反之越高。 一个系统的吞吐量和其TPS 、QPS、并发数息息相关，每个系统针对这些值都有一个相对极限值，只要其中某一个达到最大，系统的吞吐量也就到达极限了。如此时压力继续增大，系统的吞吐量反而会下降，原因是系统超负荷工作，各种资源切换等等的消耗导致系统性能下降。 关系： 所以，理解上面几个关系后，就可以推算出： QPS（TPS）= 并发数/平均响应时间 5、PV（Page View） 概念： 即每个页面的浏览次数，用户每次刷新就算一次。 6、UV（Unique Visitor） 概念：独立访客数，每天访问的用户数，此数据需要根据用户唯一标识进行去重。 7、Load（系统负载） 概念：此数据指的是Linux系统的负载情况，也就是咱们平时所用Top命令时，最上面显示的数据信息( load average: 0.1, 0.2, 0.5)。此时会显示1分钟、5分钟、15分钟的系统平均Load，很显然load average 的值越低，你的系统负荷越小。 ","link":"https://plutoyty.github.io/post/goi7K4yjE/"}]}